{
  "best_global_step": 12630,
  "best_metric": 0.8910550458715596,
  "best_model_checkpoint": "./results_lora_r8_e3/checkpoint-12630",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 12630,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 3.1027119159698486,
      "learning_rate": 9.921615201900239e-05,
      "loss": 0.5581,
      "step": 100
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 1.4545844793319702,
      "learning_rate": 9.842438638163104e-05,
      "loss": 0.3503,
      "step": 200
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.1952171325683594,
      "learning_rate": 9.763262074425971e-05,
      "loss": 0.3137,
      "step": 300
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 2.1617889404296875,
      "learning_rate": 9.684085510688836e-05,
      "loss": 0.3492,
      "step": 400
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.1396594047546387,
      "learning_rate": 9.604908946951703e-05,
      "loss": 0.3361,
      "step": 500
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.1478348970413208,
      "learning_rate": 9.525732383214568e-05,
      "loss": 0.3359,
      "step": 600
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 3.3344507217407227,
      "learning_rate": 9.446555819477435e-05,
      "loss": 0.3043,
      "step": 700
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 1.768462896347046,
      "learning_rate": 9.367379255740302e-05,
      "loss": 0.3102,
      "step": 800
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 1.1791419982910156,
      "learning_rate": 9.288202692003167e-05,
      "loss": 0.339,
      "step": 900
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 2.8077924251556396,
      "learning_rate": 9.209026128266034e-05,
      "loss": 0.2971,
      "step": 1000
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 1.570074439048767,
      "learning_rate": 9.129849564528899e-05,
      "loss": 0.311,
      "step": 1100
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 3.3130152225494385,
      "learning_rate": 9.050673000791766e-05,
      "loss": 0.2627,
      "step": 1200
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 2.2523508071899414,
      "learning_rate": 8.971496437054631e-05,
      "loss": 0.31,
      "step": 1300
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.1774747371673584,
      "learning_rate": 8.892319873317498e-05,
      "loss": 0.2836,
      "step": 1400
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 2.1088528633117676,
      "learning_rate": 8.813143309580365e-05,
      "loss": 0.2908,
      "step": 1500
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 0.7523064613342285,
      "learning_rate": 8.73396674584323e-05,
      "loss": 0.2711,
      "step": 1600
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 2.4761412143707275,
      "learning_rate": 8.654790182106097e-05,
      "loss": 0.2903,
      "step": 1700
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 2.083794116973877,
      "learning_rate": 8.575613618368963e-05,
      "loss": 0.2843,
      "step": 1800
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 0.5993406176567078,
      "learning_rate": 8.49643705463183e-05,
      "loss": 0.2912,
      "step": 1900
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 3.4659390449523926,
      "learning_rate": 8.417260490894695e-05,
      "loss": 0.2878,
      "step": 2000
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 1.931108832359314,
      "learning_rate": 8.338083927157562e-05,
      "loss": 0.3129,
      "step": 2100
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 1.3177062273025513,
      "learning_rate": 8.258907363420429e-05,
      "loss": 0.2755,
      "step": 2200
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 1.4793200492858887,
      "learning_rate": 8.179730799683294e-05,
      "loss": 0.2396,
      "step": 2300
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 3.1088995933532715,
      "learning_rate": 8.100554235946161e-05,
      "loss": 0.2672,
      "step": 2400
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 1.2473965883255005,
      "learning_rate": 8.021377672209026e-05,
      "loss": 0.2699,
      "step": 2500
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 2.5488121509552,
      "learning_rate": 7.942201108471893e-05,
      "loss": 0.2891,
      "step": 2600
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 2.1361496448516846,
      "learning_rate": 7.863024544734758e-05,
      "loss": 0.2827,
      "step": 2700
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 4.169069290161133,
      "learning_rate": 7.783847980997625e-05,
      "loss": 0.2759,
      "step": 2800
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 2.1995089054107666,
      "learning_rate": 7.704671417260492e-05,
      "loss": 0.2801,
      "step": 2900
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.7044239044189453,
      "learning_rate": 7.625494853523357e-05,
      "loss": 0.2768,
      "step": 3000
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 3.5699338912963867,
      "learning_rate": 7.546318289786224e-05,
      "loss": 0.2792,
      "step": 3100
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 0.9368802905082703,
      "learning_rate": 7.467141726049089e-05,
      "loss": 0.3055,
      "step": 3200
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 4.639177322387695,
      "learning_rate": 7.387965162311956e-05,
      "loss": 0.2452,
      "step": 3300
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 2.474774122238159,
      "learning_rate": 7.308788598574821e-05,
      "loss": 0.2846,
      "step": 3400
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 2.9847679138183594,
      "learning_rate": 7.229612034837688e-05,
      "loss": 0.29,
      "step": 3500
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 1.8924006223678589,
      "learning_rate": 7.150435471100555e-05,
      "loss": 0.2764,
      "step": 3600
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 0.563511848449707,
      "learning_rate": 7.07125890736342e-05,
      "loss": 0.2714,
      "step": 3700
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 2.5744948387145996,
      "learning_rate": 6.992082343626287e-05,
      "loss": 0.27,
      "step": 3800
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 0.6464105844497681,
      "learning_rate": 6.912905779889152e-05,
      "loss": 0.2271,
      "step": 3900
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 2.859879970550537,
      "learning_rate": 6.833729216152019e-05,
      "loss": 0.259,
      "step": 4000
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 2.24752140045166,
      "learning_rate": 6.754552652414886e-05,
      "loss": 0.2609,
      "step": 4100
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 2.666125535964966,
      "learning_rate": 6.675376088677751e-05,
      "loss": 0.269,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8818807339449541,
      "eval_f1": 0.8818867936140953,
      "eval_loss": 0.2736090421676636,
      "eval_runtime": 2.9336,
      "eval_samples_per_second": 297.244,
      "eval_steps_per_second": 9.545,
      "step": 4210
    },
    {
      "epoch": 1.0213776722090262,
      "grad_norm": 4.007555961608887,
      "learning_rate": 6.596199524940618e-05,
      "loss": 0.2689,
      "step": 4300
    },
    {
      "epoch": 1.0451306413301662,
      "grad_norm": 2.634415864944458,
      "learning_rate": 6.517022961203484e-05,
      "loss": 0.266,
      "step": 4400
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 1.7520904541015625,
      "learning_rate": 6.437846397466351e-05,
      "loss": 0.2418,
      "step": 4500
    },
    {
      "epoch": 1.0926365795724466,
      "grad_norm": 5.8148393630981445,
      "learning_rate": 6.358669833729217e-05,
      "loss": 0.2439,
      "step": 4600
    },
    {
      "epoch": 1.1163895486935866,
      "grad_norm": 1.9794344902038574,
      "learning_rate": 6.279493269992083e-05,
      "loss": 0.237,
      "step": 4700
    },
    {
      "epoch": 1.1401425178147269,
      "grad_norm": 1.2056725025177002,
      "learning_rate": 6.200316706254949e-05,
      "loss": 0.2534,
      "step": 4800
    },
    {
      "epoch": 1.1638954869358669,
      "grad_norm": 2.3039848804473877,
      "learning_rate": 6.121140142517815e-05,
      "loss": 0.257,
      "step": 4900
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.6680045127868652,
      "learning_rate": 6.0419635787806814e-05,
      "loss": 0.2563,
      "step": 5000
    },
    {
      "epoch": 1.2114014251781473,
      "grad_norm": 3.4605252742767334,
      "learning_rate": 5.9627870150435474e-05,
      "loss": 0.2606,
      "step": 5100
    },
    {
      "epoch": 1.2351543942992875,
      "grad_norm": 1.389462947845459,
      "learning_rate": 5.883610451306414e-05,
      "loss": 0.2431,
      "step": 5200
    },
    {
      "epoch": 1.2589073634204275,
      "grad_norm": 2.8295061588287354,
      "learning_rate": 5.8044338875692795e-05,
      "loss": 0.2535,
      "step": 5300
    },
    {
      "epoch": 1.2826603325415677,
      "grad_norm": 2.2268950939178467,
      "learning_rate": 5.725257323832146e-05,
      "loss": 0.259,
      "step": 5400
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 3.556370973587036,
      "learning_rate": 5.6460807600950116e-05,
      "loss": 0.2387,
      "step": 5500
    },
    {
      "epoch": 1.330166270783848,
      "grad_norm": 2.6418967247009277,
      "learning_rate": 5.566904196357878e-05,
      "loss": 0.2503,
      "step": 5600
    },
    {
      "epoch": 1.3539192399049882,
      "grad_norm": 2.7126240730285645,
      "learning_rate": 5.487727632620745e-05,
      "loss": 0.2364,
      "step": 5700
    },
    {
      "epoch": 1.3776722090261282,
      "grad_norm": 4.361169338226318,
      "learning_rate": 5.4085510688836103e-05,
      "loss": 0.2247,
      "step": 5800
    },
    {
      "epoch": 1.4014251781472684,
      "grad_norm": 0.6085024476051331,
      "learning_rate": 5.329374505146477e-05,
      "loss": 0.2514,
      "step": 5900
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 2.0354599952697754,
      "learning_rate": 5.2501979414093424e-05,
      "loss": 0.2273,
      "step": 6000
    },
    {
      "epoch": 1.4489311163895486,
      "grad_norm": 1.7071014642715454,
      "learning_rate": 5.171021377672209e-05,
      "loss": 0.2449,
      "step": 6100
    },
    {
      "epoch": 1.4726840855106889,
      "grad_norm": 4.019312381744385,
      "learning_rate": 5.091844813935075e-05,
      "loss": 0.2306,
      "step": 6200
    },
    {
      "epoch": 1.496437054631829,
      "grad_norm": 3.02909779548645,
      "learning_rate": 5.012668250197942e-05,
      "loss": 0.2398,
      "step": 6300
    },
    {
      "epoch": 1.520190023752969,
      "grad_norm": 8.785110473632812,
      "learning_rate": 4.933491686460808e-05,
      "loss": 0.244,
      "step": 6400
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 1.6240086555480957,
      "learning_rate": 4.854315122723674e-05,
      "loss": 0.2724,
      "step": 6500
    },
    {
      "epoch": 1.5676959619952493,
      "grad_norm": 0.8956191539764404,
      "learning_rate": 4.77513855898654e-05,
      "loss": 0.2228,
      "step": 6600
    },
    {
      "epoch": 1.5914489311163895,
      "grad_norm": 1.4208165407180786,
      "learning_rate": 4.695961995249407e-05,
      "loss": 0.2255,
      "step": 6700
    },
    {
      "epoch": 1.6152019002375297,
      "grad_norm": 3.163691282272339,
      "learning_rate": 4.616785431512273e-05,
      "loss": 0.2572,
      "step": 6800
    },
    {
      "epoch": 1.63895486935867,
      "grad_norm": 3.1657540798187256,
      "learning_rate": 4.537608867775139e-05,
      "loss": 0.2624,
      "step": 6900
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 1.5872074365615845,
      "learning_rate": 4.458432304038005e-05,
      "loss": 0.22,
      "step": 7000
    },
    {
      "epoch": 1.68646080760095,
      "grad_norm": 2.4058403968811035,
      "learning_rate": 4.379255740300871e-05,
      "loss": 0.2009,
      "step": 7100
    },
    {
      "epoch": 1.7102137767220902,
      "grad_norm": 2.9482762813568115,
      "learning_rate": 4.300079176563737e-05,
      "loss": 0.2607,
      "step": 7200
    },
    {
      "epoch": 1.7339667458432304,
      "grad_norm": 2.32588267326355,
      "learning_rate": 4.220902612826603e-05,
      "loss": 0.2502,
      "step": 7300
    },
    {
      "epoch": 1.7577197149643706,
      "grad_norm": 2.20741605758667,
      "learning_rate": 4.14172604908947e-05,
      "loss": 0.2262,
      "step": 7400
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 2.219968318939209,
      "learning_rate": 4.062549485352336e-05,
      "loss": 0.2362,
      "step": 7500
    },
    {
      "epoch": 1.8052256532066508,
      "grad_norm": 1.7631508111953735,
      "learning_rate": 3.9833729216152024e-05,
      "loss": 0.2461,
      "step": 7600
    },
    {
      "epoch": 1.8289786223277908,
      "grad_norm": 1.3188066482543945,
      "learning_rate": 3.9041963578780685e-05,
      "loss": 0.2547,
      "step": 7700
    },
    {
      "epoch": 1.852731591448931,
      "grad_norm": 2.9623334407806396,
      "learning_rate": 3.8250197941409345e-05,
      "loss": 0.2032,
      "step": 7800
    },
    {
      "epoch": 1.8764845605700713,
      "grad_norm": 1.397133708000183,
      "learning_rate": 3.7458432304038005e-05,
      "loss": 0.2354,
      "step": 7900
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 3.356950044631958,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.2388,
      "step": 8000
    },
    {
      "epoch": 1.9239904988123515,
      "grad_norm": 2.215542793273926,
      "learning_rate": 3.587490102929533e-05,
      "loss": 0.2574,
      "step": 8100
    },
    {
      "epoch": 1.9477434679334917,
      "grad_norm": 2.8313448429107666,
      "learning_rate": 3.508313539192399e-05,
      "loss": 0.2212,
      "step": 8200
    },
    {
      "epoch": 1.9714964370546317,
      "grad_norm": 3.3880364894866943,
      "learning_rate": 3.4291369754552654e-05,
      "loss": 0.2204,
      "step": 8300
    },
    {
      "epoch": 1.995249406175772,
      "grad_norm": 1.948826551437378,
      "learning_rate": 3.3499604117181314e-05,
      "loss": 0.2319,
      "step": 8400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8887614678899083,
      "eval_f1": 0.8886475935403243,
      "eval_loss": 0.28877079486846924,
      "eval_runtime": 2.9575,
      "eval_samples_per_second": 294.842,
      "eval_steps_per_second": 9.467,
      "step": 8420
    },
    {
      "epoch": 2.019002375296912,
      "grad_norm": 1.760087490081787,
      "learning_rate": 3.2707838479809974e-05,
      "loss": 0.2286,
      "step": 8500
    },
    {
      "epoch": 2.0427553444180524,
      "grad_norm": 3.7113091945648193,
      "learning_rate": 3.1916072842438635e-05,
      "loss": 0.2349,
      "step": 8600
    },
    {
      "epoch": 2.0665083135391926,
      "grad_norm": 1.936868667602539,
      "learning_rate": 3.11243072050673e-05,
      "loss": 0.2075,
      "step": 8700
    },
    {
      "epoch": 2.0902612826603324,
      "grad_norm": 1.557745337486267,
      "learning_rate": 3.0332541567695966e-05,
      "loss": 0.2524,
      "step": 8800
    },
    {
      "epoch": 2.1140142517814726,
      "grad_norm": 2.790705442428589,
      "learning_rate": 2.9540775930324626e-05,
      "loss": 0.2381,
      "step": 8900
    },
    {
      "epoch": 2.137767220902613,
      "grad_norm": 1.5779058933258057,
      "learning_rate": 2.8749010292953286e-05,
      "loss": 0.2231,
      "step": 9000
    },
    {
      "epoch": 2.161520190023753,
      "grad_norm": 2.698125123977661,
      "learning_rate": 2.795724465558195e-05,
      "loss": 0.2132,
      "step": 9100
    },
    {
      "epoch": 2.1852731591448933,
      "grad_norm": 4.253352165222168,
      "learning_rate": 2.716547901821061e-05,
      "loss": 0.2342,
      "step": 9200
    },
    {
      "epoch": 2.209026128266033,
      "grad_norm": 3.249330997467041,
      "learning_rate": 2.637371338083927e-05,
      "loss": 0.2344,
      "step": 9300
    },
    {
      "epoch": 2.2327790973871733,
      "grad_norm": 1.7946115732192993,
      "learning_rate": 2.558194774346793e-05,
      "loss": 0.2103,
      "step": 9400
    },
    {
      "epoch": 2.2565320665083135,
      "grad_norm": 3.3026976585388184,
      "learning_rate": 2.4790182106096595e-05,
      "loss": 0.2179,
      "step": 9500
    },
    {
      "epoch": 2.2802850356294537,
      "grad_norm": 3.102933883666992,
      "learning_rate": 2.3998416468725256e-05,
      "loss": 0.2143,
      "step": 9600
    },
    {
      "epoch": 2.304038004750594,
      "grad_norm": 0.9085621237754822,
      "learning_rate": 2.3206650831353923e-05,
      "loss": 0.2134,
      "step": 9700
    },
    {
      "epoch": 2.3277909738717337,
      "grad_norm": 3.1939966678619385,
      "learning_rate": 2.2414885193982583e-05,
      "loss": 0.2196,
      "step": 9800
    },
    {
      "epoch": 2.351543942992874,
      "grad_norm": 1.9859727621078491,
      "learning_rate": 2.1623119556611243e-05,
      "loss": 0.2217,
      "step": 9900
    },
    {
      "epoch": 2.375296912114014,
      "grad_norm": 3.2577099800109863,
      "learning_rate": 2.0831353919239907e-05,
      "loss": 0.2332,
      "step": 10000
    },
    {
      "epoch": 2.3990498812351544,
      "grad_norm": 0.8693503141403198,
      "learning_rate": 2.0039588281868568e-05,
      "loss": 0.2359,
      "step": 10100
    },
    {
      "epoch": 2.4228028503562946,
      "grad_norm": 2.058384656906128,
      "learning_rate": 1.9247822644497228e-05,
      "loss": 0.2455,
      "step": 10200
    },
    {
      "epoch": 2.446555819477435,
      "grad_norm": 2.514463424682617,
      "learning_rate": 1.8456057007125892e-05,
      "loss": 0.2341,
      "step": 10300
    },
    {
      "epoch": 2.470308788598575,
      "grad_norm": 1.7751885652542114,
      "learning_rate": 1.7664291369754556e-05,
      "loss": 0.212,
      "step": 10400
    },
    {
      "epoch": 2.494061757719715,
      "grad_norm": 3.146969795227051,
      "learning_rate": 1.6872525732383216e-05,
      "loss": 0.2042,
      "step": 10500
    },
    {
      "epoch": 2.517814726840855,
      "grad_norm": 4.557767391204834,
      "learning_rate": 1.6080760095011876e-05,
      "loss": 0.2295,
      "step": 10600
    },
    {
      "epoch": 2.5415676959619953,
      "grad_norm": 1.6391668319702148,
      "learning_rate": 1.528899445764054e-05,
      "loss": 0.2225,
      "step": 10700
    },
    {
      "epoch": 2.5653206650831355,
      "grad_norm": 3.2187576293945312,
      "learning_rate": 1.4497228820269202e-05,
      "loss": 0.2175,
      "step": 10800
    },
    {
      "epoch": 2.5890736342042757,
      "grad_norm": 2.575469970703125,
      "learning_rate": 1.3705463182897863e-05,
      "loss": 0.2246,
      "step": 10900
    },
    {
      "epoch": 2.6128266033254155,
      "grad_norm": 3.514073371887207,
      "learning_rate": 1.2913697545526523e-05,
      "loss": 0.2102,
      "step": 11000
    },
    {
      "epoch": 2.6365795724465557,
      "grad_norm": 4.791423797607422,
      "learning_rate": 1.2121931908155187e-05,
      "loss": 0.2286,
      "step": 11100
    },
    {
      "epoch": 2.660332541567696,
      "grad_norm": 3.638514995574951,
      "learning_rate": 1.1330166270783849e-05,
      "loss": 0.2248,
      "step": 11200
    },
    {
      "epoch": 2.684085510688836,
      "grad_norm": 1.5786869525909424,
      "learning_rate": 1.053840063341251e-05,
      "loss": 0.208,
      "step": 11300
    },
    {
      "epoch": 2.7078384798099764,
      "grad_norm": 2.8904573917388916,
      "learning_rate": 9.746634996041173e-06,
      "loss": 0.2307,
      "step": 11400
    },
    {
      "epoch": 2.731591448931116,
      "grad_norm": 2.782289743423462,
      "learning_rate": 8.954869358669835e-06,
      "loss": 0.1916,
      "step": 11500
    },
    {
      "epoch": 2.7553444180522564,
      "grad_norm": 2.493943214416504,
      "learning_rate": 8.163103721298495e-06,
      "loss": 0.2433,
      "step": 11600
    },
    {
      "epoch": 2.7790973871733966,
      "grad_norm": 3.0038719177246094,
      "learning_rate": 7.371338083927158e-06,
      "loss": 0.2417,
      "step": 11700
    },
    {
      "epoch": 2.802850356294537,
      "grad_norm": 3.6332502365112305,
      "learning_rate": 6.5795724465558195e-06,
      "loss": 0.2213,
      "step": 11800
    },
    {
      "epoch": 2.826603325415677,
      "grad_norm": 1.1344956159591675,
      "learning_rate": 5.7878068091844816e-06,
      "loss": 0.231,
      "step": 11900
    },
    {
      "epoch": 2.850356294536817,
      "grad_norm": 1.8998349905014038,
      "learning_rate": 4.996041171813144e-06,
      "loss": 0.223,
      "step": 12000
    },
    {
      "epoch": 2.8741092636579575,
      "grad_norm": 1.8294733762741089,
      "learning_rate": 4.204275534441805e-06,
      "loss": 0.2163,
      "step": 12100
    },
    {
      "epoch": 2.8978622327790973,
      "grad_norm": 3.6420726776123047,
      "learning_rate": 3.412509897070467e-06,
      "loss": 0.2279,
      "step": 12200
    },
    {
      "epoch": 2.9216152019002375,
      "grad_norm": 1.0099509954452515,
      "learning_rate": 2.620744259699129e-06,
      "loss": 0.2004,
      "step": 12300
    },
    {
      "epoch": 2.9453681710213777,
      "grad_norm": 5.772209167480469,
      "learning_rate": 1.8289786223277909e-06,
      "loss": 0.2401,
      "step": 12400
    },
    {
      "epoch": 2.969121140142518,
      "grad_norm": 2.9975693225860596,
      "learning_rate": 1.037212984956453e-06,
      "loss": 0.2058,
      "step": 12500
    },
    {
      "epoch": 2.992874109263658,
      "grad_norm": 4.485992908477783,
      "learning_rate": 2.454473475851148e-07,
      "loss": 0.2209,
      "step": 12600
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8910550458715596,
      "eval_f1": 0.8909745526255011,
      "eval_loss": 0.29288536310195923,
      "eval_runtime": 2.9429,
      "eval_samples_per_second": 296.307,
      "eval_steps_per_second": 9.514,
      "step": 12630
    }
  ],
  "logging_steps": 100,
  "max_steps": 12630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6805923233854464.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
